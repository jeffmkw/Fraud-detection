{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#welcome to Jeffery's world! Shoot me an email if you want to know more @ meik@purdue.edu\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load data into files\n",
    "dataset = pd.read_excel('data original.xlsx')\n",
    "dataset.drop(['Date', 'Comment','Authority?'],inplace=True,axis=1)\n",
    "dataset.columns = ['entry','text','tagger','fraud','policy','unauthorized','fee']\n",
    "\n",
    "dataset[['fraud','policy','unauthorized','fee']] = dataset[['fraud','policy','unauthorized','fee']].replace(['Yes','No'],[1,0])\n",
    "#create master tag file\n",
    "protaggers = ['lchen@vt.edu', 'jeffrey@vt.edu', 'lanham@vt.edu', 'shiva@vt.edu']\n",
    "\n",
    "pro_tag_file = dataset.loc[dataset['tagger'].isin(protaggers)]\n",
    "pro_tag_file.columns = ['entry','text','ptagger','pfraud','ppolicy','pauthorization','pfee']\n",
    "\n",
    "tag_file = dataset.loc[~dataset['tagger'].isin(protaggers)]\n",
    "\n",
    "#create the text file for it saves some ram....\n",
    "text_file = dataset[['entry','text']]\n",
    "text_file = text_file.drop_duplicates()\n",
    "\n",
    "taggerlist = set(tag_file['tagger'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "policy_tagger_dataframe_kappa = pd.DataFrame()\n",
    "authorization_tagger_dataframe_kappa = pd.DataFrame()\n",
    "fee_tagger_dataframe_kappa = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraud good taggers count:  31\n",
      "fraudfile.shape:  (4670, 4)\n",
      "fraudfile.shape:  (3060, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:32: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraudfile.shape:  (3060, 3)\n"
     ]
    }
   ],
   "source": [
    "#this part is for fraud only\n",
    "#create good tagger list and another dataframe with their kappa\n",
    "fraud_tagger_dataframe_kappa = pd.DataFrame()\n",
    "fraud_goodtagger = []\n",
    "\n",
    "#note: there is no kappa score provided by professor. So I am the authority :D\n",
    "for tagger in taggerlist:\n",
    "    temp_tagged_file = tag_file.loc[tag_file['tagger']==tagger]\n",
    "\n",
    "    comparefile = pd.merge(temp_tagged_file, pro_tag_file, how='inner', on=['entry'])\n",
    "\n",
    "    kappa = sklearn.metrics.cohen_kappa_score(comparefile['fraud'],comparefile['pfraud'])\n",
    "    if kappa >= 0.4:\n",
    "        fraud_goodtagger.append(tagger)\n",
    "        temp_tagger = [[tagger,kappa]]\n",
    "        fraud_tagger_dataframe_kappa = fraud_tagger_dataframe_kappa.append(temp_tagger)\n",
    "    gc.collect\n",
    "\n",
    "#write the kappa of taggers to file\n",
    "fraud_tagger_dataframe_kappa.columns = ['tagger','kappa']\n",
    "print('fraud good taggers count: ',len(fraud_tagger_dataframe_kappa))\n",
    "writer = pd.ExcelWriter('fraud_tagger_dataframe_kappa.xlsx')\n",
    "fraud_tagger_dataframe_kappa.to_excel(writer)\n",
    "writer.save()\n",
    "\n",
    "fraudfile = dataset.loc[dataset['tagger'].isin(fraud_goodtagger)]\n",
    "fraudfile.drop(['policy','unauthorized','fee'],inplace=1,axis=1)\n",
    "print('fraudfile.shape: ', fraudfile.shape)\n",
    "\n",
    "#merge fraud dataset by first\n",
    "fraudfile_analysis = pd.merge(fraudfile,fraud_tagger_dataframe_kappa,on='tagger',how='left')\n",
    "fraudfile_analysis.sort(['entry','kappa'],ascending=[True,False])\n",
    "fraudfile_analysis_first_sort = fraudfile_analysis.groupby('entry').first()\n",
    "fraudfile_analysis_first_sort.drop('kappa',inplace=1,axis = 1)\n",
    "print('fraudfile.shape: ', fraudfile_analysis_first_sort.shape)\n",
    "\n",
    "#write first-selected doc to file\n",
    "writer = pd.ExcelWriter('fraudfile_analysis_first_sort.xlsx')\n",
    "fraudfile_analysis_first_sort.to_excel(writer)\n",
    "writer.save()\n",
    "\n",
    "\n",
    "#merge fraud dataset by voting (average)\n",
    "temp = fraudfile_analysis.groupby('entry', as_index=False)['fraud'].mean()\n",
    "temp.columns=['entry','score']\n",
    "temp['fraud'] = np.where(temp['score']>=0.5, 1,0)\n",
    "fraudfile_analysis_mean_merge = pd.merge(temp,text_file,on='entry',how='left')\n",
    "fraudfile_analysis_mean_merge.drop('score',axis=1,inplace=True)\n",
    "\n",
    "#writed average-selected doc to file\n",
    "print('fraudfile.shape: ', fraudfile_analysis_mean_merge.shape)\n",
    "writer = pd.ExcelWriter('fraudfile_analysis_mean_merge.xlsx')\n",
    "fraudfile_analysis_mean_merge.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy good taggers count:  23\n",
      "policyfile.shape:  (3400, 4)\n",
      "policyfile.shape:  (2408, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:31: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policyfile.shape:  (2408, 3)\n"
     ]
    }
   ],
   "source": [
    "#this part is for policy only\n",
    "#create good tagger list and another dataframe with their kappa\n",
    "policy_tagger_dataframe_kappa = pd.DataFrame()\n",
    "policy_goodtagger = []\n",
    "\n",
    "for tagger in taggerlist:\n",
    "    temp_tagged_file = tag_file.loc[tag_file['tagger']==tagger]\n",
    "\n",
    "    comparefile = pd.merge(temp_tagged_file, pro_tag_file, how='inner', on=['entry'])\n",
    "\n",
    "    kappa = sklearn.metrics.cohen_kappa_score(comparefile['policy'],comparefile['ppolicy'])\n",
    "    if kappa >= 0.4:\n",
    "        policy_goodtagger.append(tagger)\n",
    "        temp_tagger = [[tagger,kappa]]\n",
    "        policy_tagger_dataframe_kappa = policy_tagger_dataframe_kappa.append(temp_tagger)\n",
    "    gc.collect\n",
    "\n",
    "#write the kappa of taggers to file\n",
    "policy_tagger_dataframe_kappa.columns = ['tagger','kappa']\n",
    "print('policy good taggers count: ',len(policy_tagger_dataframe_kappa))\n",
    "writer = pd.ExcelWriter('policy_tagger_dataframe_kappa.xlsx')\n",
    "policy_tagger_dataframe_kappa.to_excel(writer)\n",
    "writer.save()\n",
    "\n",
    "policyfile = dataset.loc[dataset['tagger'].isin(policy_goodtagger)]\n",
    "policyfile.drop(['fraud','unauthorized','fee'],inplace=1,axis=1)\n",
    "print('policyfile.shape: ', policyfile.shape)\n",
    "\n",
    "#merge policy dataset by first\n",
    "policyfile_analysis = pd.merge(policyfile,policy_tagger_dataframe_kappa,on='tagger',how='left')\n",
    "policyfile_analysis.sort(['entry','kappa'],ascending=[True,False])\n",
    "policyfile_analysis_first_sort = policyfile_analysis.groupby('entry').first()\n",
    "policyfile_analysis_first_sort.drop('kappa',inplace=1,axis = 1)\n",
    "print('policyfile.shape: ', policyfile_analysis_first_sort.shape)\n",
    "\n",
    "#write first-selected doc to file\n",
    "writer = pd.ExcelWriter('policyfile_analysis_first_sort.xlsx')\n",
    "policyfile_analysis_first_sort.to_excel(writer)\n",
    "writer.save()\n",
    "\n",
    "\n",
    "#merge policy dataset by voting (average)\n",
    "temp = policyfile_analysis.groupby('entry', as_index=False)['policy'].mean()\n",
    "temp.columns=['entry','score']\n",
    "temp['policy'] = np.where(temp['score']>=0.5, 1,0)\n",
    "policyfile_analysis_mean_merge = pd.merge(temp,text_file,on='entry',how='left')\n",
    "policyfile_analysis_mean_merge.drop('score',axis=1,inplace=True)\n",
    "\n",
    "#writed average-selected doc to file\n",
    "print('policyfile.shape: ', policyfile_analysis_mean_merge.shape)\n",
    "writer = pd.ExcelWriter('policyfile_analysis_mean_merge.xlsx')\n",
    "policyfile_analysis_mean_merge.to_excel(writer)\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'punauthorized'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1944\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1945\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1946\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'punauthorized'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-904b630be615>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcomparefile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_tagged_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpro_tag_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entry'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mkappa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcohen_kappa_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomparefile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unauthorized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcomparefile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'punauthorized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkappa\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0munauthorized_goodtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1995\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1997\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2002\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2004\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3290\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3291\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3292\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1945\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'punauthorized'"
     ]
    }
   ],
   "source": [
    "#this part is for unauthorized only\n",
    "#create good tagger list and another dataframe with their kappa\n",
    "unauthorized_tagger_dataframe_kappa = pd.DataFrame()\n",
    "unauthorized_goodtagger = []\n",
    "\n",
    "#note: there is no kappa score provided by professor. So I am the authority :D\n",
    "for tagger in taggerlist:\n",
    "    temp_tagged_file = tag_file.loc[tag_file['tagger']==tagger]\n",
    "\n",
    "    comparefile = pd.merge(temp_tagged_file, pro_tag_file, how='inner', on=['entry'])\n",
    "\n",
    "    kappa = sklearn.metrics.cohen_kappa_score(comparefile['unauthorized'],comparefile['punauthorized'])\n",
    "    if kappa >= 0.4:\n",
    "        unauthorized_goodtagger.append(tagger)\n",
    "        temp_tagger = [[tagger,kappa]]\n",
    "        unauthorized_tagger_dataframe_kappa = unauthorized_tagger_dataframe_kappa.append(temp_tagger)\n",
    "    gc.collect\n",
    "\n",
    "#write the kappa of taggers to file\n",
    "unauthorized_tagger_dataframe_kappa.columns = ['tagger','kappa']\n",
    "print('unauthorized good taggers count: ',len(unauthorized_tagger_dataframe_kappa))\n",
    "writer = pd.ExcelWriter('unauthorized_tagger_dataframe_kappa.xlsx')\n",
    "unauthorized_tagger_dataframe_kappa.to_excel(writer)\n",
    "writer.save()\n",
    "\n",
    "unauthorizedfile = dataset.loc[dataset['tagger'].isin(unauthorized_goodtagger)]\n",
    "unauthorizedfile.drop(['policy','fraud','fee'],inplace=1,axis=1)\n",
    "print('unauthorizedfile.shape: ', unauthorizedfile.shape)\n",
    "\n",
    "#merge unauthorized dataset by first\n",
    "unauthorizedfile_analysis = pd.merge(unauthorizedfile,unauthorized_tagger_dataframe_kappa,on='tagger',how='left')\n",
    "unauthorizedfile_analysis.sort(['entry','kappa'],ascending=[True,False])\n",
    "unauthorizedfile_analysis_first_sort = unauthorizedfile_analysis.groupby('entry').first()\n",
    "unauthorizedfile_analysis_first_sort.drop('kappa',inplace=1,axis = 1)\n",
    "print('unauthorizedfile.shape: ', unauthorizedfile_analysis_first_sort.shape)\n",
    "\n",
    "#write first-selected doc to file\n",
    "writer = pd.ExcelWriter('unauthorizedfile_analysis_first_sort.xlsx')\n",
    "unauthorizedfile_analysis_first_sort.to_excel(writer)\n",
    "writer.save()\n",
    "\n",
    "\n",
    "#merge unauthorized dataset by voting (average)\n",
    "temp = unauthorizedfile_analysis.groupby('entry', as_index=False)['unauthorized'].mean()\n",
    "temp.columns=['entry','score']\n",
    "temp['unauthorized'] = np.where(temp['score']>=0.5, 1,0)\n",
    "unauthorizedfile_analysis_mean_merge = pd.merge(temp,text_file,on='entry',how='left')\n",
    "unauthorizedfile_analysis_mean_merge.drop('score',axis=1,inplace=True)\n",
    "\n",
    "#writed average-selected doc to file\n",
    "print('unauthorizedfile.shape: ', unauthorizedfile_analysis_mean_merge.shape)\n",
    "writer = pd.ExcelWriter('unauthorizedfile_analysis_mean_merge.xlsx')\n",
    "unauthorizedfile_analysis_mean_merge.to_excel(writer)\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this part is for fee only\n",
    "#create good tagger list and another dataframe with their kappa\n",
    "fee_tagger_dataframe_kappa = pd.DataFrame()\n",
    "fee_goodtagger = []\n",
    "\n",
    "#note: there is no kappa score provided by professor. So I am the authority :D\n",
    "for tagger in taggerlist:\n",
    "    temp_tagged_file = tag_file.loc[tag_file['tagger']==tagger]\n",
    "\n",
    "    comparefile = pd.merge(temp_tagged_file, pro_tag_file, how='inner', on=['entry'])\n",
    "\n",
    "    kappa = sklearn.metrics.cohen_kappa_score(comparefile['fee'],comparefile['pfee'])\n",
    "    if kappa >= 0.4:\n",
    "        fee_goodtagger.append(tagger)\n",
    "        temp_tagger = [[tagger,kappa]]\n",
    "        fee_tagger_dataframe_kappa = fee_tagger_dataframe_kappa.append(temp_tagger)\n",
    "    gc.collect\n",
    "\n",
    "#write the kappa of taggers to file\n",
    "fee_tagger_dataframe_kappa.columns = ['tagger','kappa']\n",
    "print('fee good taggers count: ',len(fee_tagger_dataframe_kappa))\n",
    "writer = pd.ExcelWriter('fee_tagger_dataframe_kappa.xlsx')\n",
    "fee_tagger_dataframe_kappa.to_excel(writer)\n",
    "writer.save()\n",
    "\n",
    "feefile = dataset.loc[dataset['tagger'].isin(fee_goodtagger)]\n",
    "feefile.drop(['policy','unauthorized','fraud'],inplace=1,axis=1)\n",
    "print('feefile.shape: ', feefile.shape)\n",
    "\n",
    "#merge fee dataset by first\n",
    "feefile_analysis = pd.merge(feefile,fee_tagger_dataframe_kappa,on='tagger',how='left')\n",
    "feefile_analysis.sort(['entry','kappa'],ascending=[True,False])\n",
    "feefile_analysis_first_sort = feefile_analysis.groupby('entry').first()\n",
    "feefile_analysis_first_sort.drop('kappa',inplace=1,axis = 1)\n",
    "print('feefile.shape: ', feefile_analysis_first_sort.shape)\n",
    "\n",
    "#write first-selected doc to file\n",
    "writer = pd.ExcelWriter('feefile_analysis_first_sort.xlsx')\n",
    "feefile_analysis_first_sort.to_excel(writer)\n",
    "writer.save()\n",
    "\n",
    "\n",
    "#merge fee dataset by voting (average)\n",
    "temp = feefile_analysis.groupby('entry', as_index=False)['fee'].mean()\n",
    "temp.columns=['entry','score']\n",
    "temp['fee'] = np.where(temp['score']>=0.5, 1,0)\n",
    "feefile_analysis_mean_merge = pd.merge(temp,text_file,on='entry',how='left')\n",
    "feefile_analysis_mean_merge.drop('score',axis=1,inplace=True)\n",
    "\n",
    "#writed average-selected doc to file\n",
    "print('feefile.shape: ', feefile_analysis_mean_merge.shape)\n",
    "writer = pd.ExcelWriter('feefile_analysis_mean_merge.xlsx')\n",
    "feefile_analysis_mean_merge.to_excel(writer)\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fraud_tagger_dataframe_kappa.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fraudfile_analysis.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#expereiment field\n",
    "tag_file.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_file.head(5)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
